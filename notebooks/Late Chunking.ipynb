{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0308333-e466-4375-a72c-9f4799777ae1",
   "metadata": {},
   "source": [
    "# Late Chunking\n",
    "\n",
    "Below is the implementation of late chunking from the paper - [Late Chunking: Contextual Chunk Embeddings Using Long-Context Embedding Models](https://arxiv.org/abs/2409.04701). The chunking method allows us to retain contextual information from the whole document within the chunks.\n",
    "\n",
    "The code runs through it step by step before wrapping in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "917ece24-fae9-4e4f-9fb1-be4b1475c8c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd88a481-c2a0-4180-a7e8-713db63124d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e74e0-fdd4-43b7-8426-a0bfdf0d9bc5",
   "metadata": {},
   "source": [
    "## Sample Text\n",
    "\n",
    "Below i have some sample text as well as different methods to create the chunks from this text:\n",
    "* Simple Chunks - Keep only the body of text between each header - this will be used for a text search.\n",
    "* Title Chunks - Keep the body of text and the Markdown header - this will be a slightly more enriched search and still findable within the main text.\n",
    "* Enriched Chunks - This uses the main header and subheader as metadata, this cannot be searched so is used as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f030906e-f635-459c-be03-609356f9c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"\"\"\n",
    "# Coffee Machine Maintenance\n",
    "\n",
    "##   Daily Cleaning Routine\n",
    "\n",
    "After each use, the coffee machine should be cleaned to prevent buildup of coffee oils and residue.\n",
    "This includes emptying and rinsing the carafe, removing used coffee grounds, and wiping down the exterior and drip tray.\n",
    "Ensuring these steps are done daily helps maintain hygiene and keeps the machine functioning efficiently.\n",
    "\n",
    "##  Descaling and Internal Maintenance\n",
    "\n",
    "The machine should be descaled approximately once a month, or more frequently if hard water is used.\n",
    "Use a descaling solution or a mixture of water and white vinegar, following the manufacturer’s instructions.\n",
    "This process removes mineral deposits from internal components, which helps maintain water flow and brewing temperature.\n",
    "\n",
    "## Filter and Component Checks\n",
    "\n",
    "Regularly inspect and clean or replace the coffee filter, whether it’s reusable or disposable.\n",
    "Additionally, check the water reservoir and any removable parts for signs of mould or buildup.\n",
    "Keeping these components clean ensures consistent coffee quality and extends the lifespan of the machine.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b36f20-5cc1-410e-869a-037a81774c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chunk_1 = \"\"\"After each use, the coffee machine should be cleaned to prevent buildup of coffee oils and residue.\n",
    "This includes emptying and rinsing the carafe, removing used coffee grounds, and wiping down the exterior and drip tray.\n",
    "Ensuring these steps are done daily helps maintain hygiene and keeps the machine functioning efficiently.\n",
    "\"\"\"\n",
    "\n",
    "simple_chunk_2 = \"\"\"The machine should be descaled approximately once a month, or more frequently if hard water is used.\n",
    "Use a descaling solution or a mixture of water and white vinegar, following the manufacturer’s instructions.\n",
    "This process removes mineral deposits from internal components, which helps maintain water flow and brewing temperature.\n",
    "\"\"\"\n",
    "\n",
    "simple_chunk_3 = \"\"\"Regularly inspect and clean or replace the coffee filter, whether it’s reusable or disposable.\n",
    "Additionally, check the water reservoir and any removable parts for signs of mould or buildup.\n",
    "Keeping these components clean ensures consistent coffee quality and extends the lifespan of the machine.\n",
    "\"\"\"\n",
    "\n",
    "simple_split_chunks = [simple_chunk_1, simple_chunk_2, simple_chunk_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f28dfac-1d40-4afa-8bd1-e0ca0105161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_chunk_1 = \"\"\"\n",
    "##   Daily Cleaning Routine\n",
    "\n",
    "After each use, the coffee machine should be cleaned to prevent buildup of coffee oils and residue.\n",
    "This includes emptying and rinsing the carafe, removing used coffee grounds, and wiping down the exterior and drip tray.\n",
    "Ensuring these steps are done daily helps maintain hygiene and keeps the machine functioning efficiently.\n",
    "\"\"\"\n",
    "\n",
    "title_chunk_2 = \"\"\"\n",
    "##  Descaling and Internal Maintenance\n",
    "\n",
    "The machine should be descaled approximately once a month, or more frequently if hard water is used.\n",
    "Use a descaling solution or a mixture of water and white vinegar, following the manufacturer’s instructions.\n",
    "This process removes mineral deposits from internal components, which helps maintain water flow and brewing temperature.\n",
    "\"\"\"\n",
    "\n",
    "title_chunk_3 = \"\"\"\n",
    "## Filter and Component Checks\n",
    "\n",
    "Regularly inspect and clean or replace the coffee filter, whether it’s reusable or disposable.\n",
    "Additionally, check the water reservoir and any removable parts for signs of mould or buildup.\n",
    "Keeping these components clean ensures consistent coffee quality and extends the lifespan of the machine.\n",
    "\"\"\"\n",
    "\n",
    "title_split_chunks = [title_chunk_1, title_chunk_2, title_chunk_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fab2fcda-c183-4dfc-a137-323952656fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_chunk_1 = \"\"\"\n",
    "Title: Coffee Machine Maintenance\n",
    "Subtitle: Daily Cleaning Routine\n",
    "Text: After each use, the coffee machine should be cleaned to prevent buildup of coffee oils and residue.\n",
    "This includes emptying and rinsing the carafe, removing used coffee grounds, and wiping down the exterior and drip tray.\n",
    "Ensuring these steps are done daily helps maintain hygiene and keeps the machine functioning efficiently.\n",
    "\"\"\"\n",
    "\n",
    "enriched_chunk_2 = \"\"\"\n",
    "Title: Coffee Machine Maintenance\n",
    "Subtitle: Descaling and Internal Maintenance\n",
    "Text: The machine should be descaled approximately once a month, or more frequently if hard water is used.\n",
    "Use a descaling solution or a mixture of water and white vinegar, following the manufacturer’s instructions.\n",
    "This process removes mineral deposits from internal components, which helps maintain water flow and brewing temperature.\n",
    "\"\"\"\n",
    "\n",
    "enriched_chunk_3 = \"\"\"\n",
    "Title: Coffee Machine Maintenance\n",
    "Subtitle: Filter and Component Checks\n",
    "Text: Regularly inspect and clean or replace the coffee filter, whether it’s reusable or disposable.\n",
    "Additionally, check the water reservoir and any removable parts for signs of mould or buildup.\n",
    "Keeping these components clean ensures consistent coffee quality and extends the lifespan of the machine.\n",
    "\"\"\"\n",
    "\n",
    "enriched_split_chunks = [enriched_chunk_1, enriched_chunk_2, enriched_chunk_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e37e5-9f47-438b-bbe4-6e283094c106",
   "metadata": {},
   "source": [
    "## Simple Embedding Function\n",
    "\n",
    "Here we define a function for embedding the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94813979-db33-499f-9531-eec527893178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_embedding(text, model_name=model_name):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    # Load the model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Encode the input text\n",
    "    query_embeddings = model.encode(text)\n",
    "\n",
    "    # Convert to list\n",
    "    embedding_list = query_embeddings.tolist()\n",
    "\n",
    "    # Ensure embedding_list is a list of lists\n",
    "    if isinstance(embedding_list[0], (int, float)):\n",
    "        embedding_list = [embedding_list]\n",
    "\n",
    "    return embedding_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb8946-d461-40ba-9676-5207f1483efa",
   "metadata": {},
   "source": [
    "### Perform Simple Embedding on the Text Chunks Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "406470fb-da02-4aaf-8546-c82890640eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chunk_embedding = simple_embedding(simple_split_chunks)\n",
    "title_chunk_embedding = simple_embedding(title_split_chunks)\n",
    "enriched_chunk_embedding = simple_embedding(enriched_split_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690e792-2737-4fa6-a150-7306d8206e56",
   "metadata": {},
   "source": [
    "## Late Chunking Function\n",
    "\n",
    "Below we have a simple late chunking function which chunks based on a fixed chunk size of 50 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f6c7310-3812-4ebc-830c-80e656c7dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def late_chunking(text, chunk_size = 50, model=model, tokenizer=tokenizer):\n",
    "    \"\"\"Function to perform the Late Chunking method of embedding\"\"\"\n",
    "\n",
    "    # Encode the whole text and ensure the offsets for tokens are stored\n",
    "    encodings = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=True,\n",
    "        truncation=False\n",
    "    )\n",
    "\n",
    "    # Convert offsets from Tensor to numpy array\n",
    "    offsets = encodings[\"offset_mapping\"][0].numpy()\n",
    "    num_tokens = len(offsets)\n",
    "\n",
    "    token_embeddings = []\n",
    "\n",
    "    # Loop through tokens and embed token by token\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        embs = outputs.last_hidden_state.squeeze()\n",
    "        token_embeddings = embs.tolist()\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    # Now loop through the token embeddings and create the chunks by number of tokens.\n",
    "    # Then pool the embeddings and take the average point wise across the embeddings for each chunk\n",
    "    for i in range(0, num_tokens, chunk_size):\n",
    "    \n",
    "        start_token = i\n",
    "        end_token = min(i + chunk_size, num_tokens - 1)\n",
    "    \n",
    "        start_char = offsets[start_token][0]\n",
    "        end_char = offsets[end_token][1] if end_token < num_tokens else offsets[-1][1]\n",
    "\n",
    "        chunk_text = text[start_char:end_char].strip()\n",
    "        chunk_embs = token_embeddings[start_token:end_token+1]\n",
    "        # Take the mean for each position in all embedding vectors for each chunk\n",
    "        chunk_emb = torch.tensor(chunk_embs).mean(dim=0).tolist()\n",
    "        \n",
    "        chunks.append({\n",
    "            \"text\": chunk_text,\n",
    "            \"embedding\": chunk_emb\n",
    "        })\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fbb4c1-c722-4656-b212-2632065d15b9",
   "metadata": {},
   "source": [
    "## Custom Late Chunking Function\n",
    "\n",
    "What if we want to chunk differently than a fixed length? Here i create a slightly more sophisticated couple of functions which search though a larger text for a string and find the character positions of each and then use those as the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6903a337-566d-4f37-9a86-08de749b90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_range_for_text(text, target_text, tokenizer=tokenizer):\n",
    "    \"\"\"Helper function to find the token range corresponding to a target text substring\"\"\"\n",
    "    \n",
    "    # Encode the entire text to get the original token offsets\n",
    "    encodings = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=True,\n",
    "        truncation=False\n",
    "    )\n",
    "    offsets = encodings[\"offset_mapping\"][0].numpy()\n",
    "\n",
    "    # Find the character start and end of the target text in the original text\n",
    "    target_start = text.find(target_text)\n",
    "    if target_start == -1:\n",
    "        raise ValueError(\"Target text not found in the original text.\")\n",
    "    target_end = target_start + len(target_text)\n",
    "\n",
    "    # Locate the tokens that cover the target character range\n",
    "    start_token = None\n",
    "    end_token = None\n",
    "    for i, (char_start, char_end) in enumerate(offsets):\n",
    "        if char_start <= target_start < char_end:\n",
    "            start_token = i\n",
    "        if char_start < target_end <= char_end:\n",
    "            end_token = i\n",
    "            break\n",
    "\n",
    "    if start_token is None or end_token is None:\n",
    "        raise ValueError(\"Target text spans beyond token boundaries.\")\n",
    "\n",
    "    return (start_token, end_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62a2ea7d-dc28-4a87-921d-01b8e16e1967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def late_chunking_with_ranges(\n",
    "    text, \n",
    "    chunk_size=50, \n",
    "    custom_chunk_ranges=None,\n",
    "    model=model, \n",
    "    tokenizer=tokenizer\n",
    "):\n",
    "    \"\"\"Function to perform the Late Chunking method of embedding with optional custom chunk boundaries\"\"\"\n",
    "\n",
    "    # Encode the whole text and ensure the offsets for tokens are stored\n",
    "    encodings = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=True,\n",
    "        truncation=False\n",
    "    )\n",
    "\n",
    "    # Convert offsets from Tensor to numpy array\n",
    "    offsets = encodings[\"offset_mapping\"][0].numpy()\n",
    "    num_tokens = len(offsets)\n",
    "\n",
    "    token_embeddings = []\n",
    "\n",
    "    # Loop through tokens and embed token by token\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        embs = outputs.last_hidden_state.squeeze()\n",
    "        token_embeddings = embs.tolist()\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    # Determine chunk ranges\n",
    "    if custom_chunk_ranges is not None:\n",
    "        # Use custom defined chunk ranges\n",
    "        chunk_ranges = custom_chunk_ranges\n",
    "    else:\n",
    "        # Default to chunking by fixed size\n",
    "        chunk_ranges = [(i, min(i + chunk_size, num_tokens - 1)) for i in range(0, num_tokens, chunk_size)]\n",
    "\n",
    "    # Now process each defined chunk range\n",
    "    for start_token, end_token in chunk_ranges:\n",
    "        start_char = offsets[start_token][0]\n",
    "        end_char = offsets[end_token][1] if end_token < num_tokens else offsets[-1][1]\n",
    "\n",
    "        chunk_text = text[start_char:end_char].strip()\n",
    "        chunk_embs = token_embeddings[start_token:end_token+1]\n",
    "        # Take the mean for each position in all embedding vectors for each chunk\n",
    "        chunk_emb = torch.tensor(chunk_embs).mean(dim=0).tolist()\n",
    "        \n",
    "        chunks.append({\n",
    "            \"text\": chunk_text,\n",
    "            \"embedding\": chunk_emb\n",
    "        })\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481ef596-2e3e-4699-a94d-308aa4033b5b",
   "metadata": {},
   "source": [
    "## Get the Ranges for Chunks within Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182a95d-3f3b-4bc6-affb-c29e8e081379",
   "metadata": {},
   "source": [
    "### Simple Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1695d4c0-56ed-4abe-ae02-dbf60ef7558f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 72), (81, 138), (145, 195)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_1_range = get_token_range_for_text(text, simple_chunk_1)\n",
    "chunk_2_range = get_token_range_for_text(text, simple_chunk_2)\n",
    "chunk_3_range = get_token_range_for_text(text, simple_chunk_3)\n",
    "\n",
    "chunk_ranges = [chunk_1_range, chunk_2_range, chunk_3_range]\n",
    "chunk_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f67fd57-aa21-4e70-a2d1-b6857ebabfa4",
   "metadata": {},
   "source": [
    "### Title Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb1afffb-6a5e-4965-94f3-51a1013dabdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 72), (72, 138), (138, 195)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_title_1_range = get_token_range_for_text(text, title_chunk_1)\n",
    "chunk_title_2_range = get_token_range_for_text(text, title_chunk_2)\n",
    "chunk_title_3_range = get_token_range_for_text(text, title_chunk_3)\n",
    "\n",
    "chunk_title_ranges = [chunk_title_1_range, chunk_title_2_range, chunk_title_3_range]\n",
    "chunk_title_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc5938-6dee-40d7-ba90-64b47ee56f80",
   "metadata": {},
   "source": [
    "## Perform Late Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b5ceb-02c0-4f6a-a40d-e5e64e0b64f3",
   "metadata": {},
   "source": [
    "### Without Specific Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52c82a00-e24c-4761-ae98-c2b29024a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Coffee Machine Maintenance\n",
      "\n",
      "##   Daily Cleaning Routine\n",
      "\n",
      "After each use, the coffee machine should be cleaned to prevent buildup of coffee oils and residue.\n",
      "This includes emptying and rinsing the carafe, removing used coffee grounds, and wiping down the\n",
      "[-0.1366955190896988, -6.695122718811035, -0.15915973484516144, 0.11862444132566452, -2.3169548511505127]\n"
     ]
    }
   ],
   "source": [
    "result = late_chunking(text)\n",
    "\n",
    "print(result[0]['text'])\n",
    "print(result[0]['embedding'][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f285b-f419-4977-bc53-e241f7316547",
   "metadata": {},
   "source": [
    "### With Simple Text Range (No Headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e4dca03-2b3f-4523-8efb-b81a38bdd7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After each use, the coffee machine should be cleaned to prevent buildup of coffee oils and residue.\n",
      "This includes emptying and rinsing the carafe, removing used coffee grounds, and wiping down the exterior and drip tray.\n",
      "Ensuring these steps are done daily helps maintain hygiene and keeps the machine functioning efficiently.\n",
      "[-0.17096972465515137, -6.924577713012695, -0.03905126079916954, 1.0475043058395386, -1.8993895053863525]\n"
     ]
    }
   ],
   "source": [
    "simple_result = late_chunking_with_ranges(text, custom_chunk_ranges=chunk_ranges)\n",
    "\n",
    "print(simple_result[0]['text'])\n",
    "print(simple_result[0]['embedding'][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765f3c12-b672-434c-80ff-5fff40b624cf",
   "metadata": {},
   "source": [
    "### With Title Text Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6abdabed-9629-4548-9ece-b2b7aa157f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##   Daily Cleaning Routine\n",
      "\n",
      "After each use, the coffee machine should be cleaned to prevent buildup of coffee oils and residue.\n",
      "This includes emptying and rinsing the carafe, removing used coffee grounds, and wiping down the exterior and drip tray.\n",
      "Ensuring these steps are done daily helps maintain hygiene and keeps the machine functioning efficiently.\n",
      "[-0.18933133780956268, -6.56510591506958, -0.11924945563077927, 0.9724718928337097, -1.7468141317367554]\n"
     ]
    }
   ],
   "source": [
    "title_result = late_chunking_with_ranges(text, custom_chunk_ranges=chunk_title_ranges)\n",
    "\n",
    "print(title_result[0]['text'])\n",
    "print(title_result[0]['embedding'][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b10b3d-acd4-47fc-8250-04a8399f82da",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "Below is the function to calculate the cosine similarity, which is the angle between two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac265cae-63c2-44ac-8e9b-7907fdb59ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a: list[float], b: list[float]) -> float:\n",
    "    arr1 = np.array(a)\n",
    "    arr2 = np.array(b)\n",
    "    return float(arr1.dot(arr2) / (np.linalg.norm(arr1) * np.linalg.norm(arr2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde36bd-6ec6-40ef-8d5a-f01d664a15fe",
   "metadata": {},
   "source": [
    "## Similarity Scoring with Question Example\n",
    "\n",
    "Below i utilise the embeddings calculated and a sample question to check the similarity between question and chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8529a796-ecbd-4c34-8475-3ab5b5563755",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do i clean the drinks machine?\"\n",
    "question_embed = simple_embedding(question)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e691c2-5c53-4e85-9135-efe093d28142",
   "metadata": {},
   "source": [
    "### Simple Embedding Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb8ea5d8-1577-4c92-bfee-fdeaac0d45b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6121795947891503\n",
      "0.5415360480186737\n",
      "0.5336931622388909\n"
     ]
    }
   ],
   "source": [
    "for chunk in simple_chunk_embedding:\n",
    "    sim = cosine_similarity(question_embed, chunk)\n",
    "    print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42c1582d-d21e-4957-9451-5fec6a757ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5889322870180265\n",
      "0.5167286511227129\n",
      "0.5083043711352284\n"
     ]
    }
   ],
   "source": [
    "for chunk in title_chunk_embedding:\n",
    "    sim = cosine_similarity(question_embed, chunk)\n",
    "    print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22d4f87f-8ea6-4277-8050-609650b180af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5611430670921256\n",
      "0.5320672727309541\n",
      "0.4838873749405817\n"
     ]
    }
   ],
   "source": [
    "for chunk in enriched_chunk_embedding:\n",
    "    sim = cosine_similarity(question_embed, chunk)\n",
    "    print(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648b9b9d-1df6-4cd4-b904-d0529241b6a3",
   "metadata": {},
   "source": [
    "### Late Chunking Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed21cf9d-6ec8-49c4-b1d8-7bb262c85d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6087372591271948\n",
      "0.4980847456652066\n",
      "0.5025916297033763\n"
     ]
    }
   ],
   "source": [
    "for res in simple_result:\n",
    "    embedding = res['embedding']\n",
    "    sim = cosine_similarity(question_embed, embedding)\n",
    "    print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "905f1948-f008-4203-b444-e446f287c307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6235854485507689\n",
      "0.5277800851847356\n",
      "0.5138187483650648\n"
     ]
    }
   ],
   "source": [
    "for res in title_result:\n",
    "    embedding = res['embedding']\n",
    "    sim = cosine_similarity(question_embed, embedding)\n",
    "    print(sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "av_dists",
   "language": "python",
   "name": "av_dists"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
